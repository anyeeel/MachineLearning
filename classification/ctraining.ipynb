#import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv(r"C:\Users\Anjel69\Desktop\cs2\archive\Symptom2Disease.csv")
df.drop("Unnamed: 0",inplace=True,axis=1)
df

df.info()

df.isnull().sum()

for col in df.columns:
    print(col,": ",df[col].unique(),"\n")

#data cleaning
nltk.download('punkt')
nltk.download('stopwords')

#set of English stop words
stop_words = set(stopwords.words('english'))

def clean_text(sent):
    #remove punctuations
    sent = sent.translate(str.maketrans('','',string.punctuation)).strip()
    
    #remove stopwords
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(sent)
    words = [word for word in words if word not in stop_words]
    
    return " ".join(words).lower()

# apply clean_text on text column of df
df["text"] = df["text"].apply(clean_text)


# create word cloud to vizualize frequent words in our dataset
all_text = " ".join(df["text"])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

#Split data into train and test set
X_train, X_test, y_train, y_test = train_test_split(df["text"], df["label"], test_size=0.2, random_state=42)

# use tfidf for text vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=1500)

tfidf_train = tfidf_vectorizer.fit_transform(X_train).toarray()
tfidf_test = tfidf_vectorizer.transform(X_test).toarray()

# knn will be our first model 
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(tfidf_train, y_train)

predictions = knn.predict(tfidf_test)

def report(y_test,predictions):
    """Function to create classification report"""
    accuracy = accuracy_score(y_test, predictions)
    print(f'Accuracy: {accuracy:.2f}')
    print(classification_report(y_test, predictions))

report(y_test,predictions)

def make_pred(model,text):
    """Function to make prediction on single data instance"""
    text = clean_text(text)
    tfidf = tfidf_vectorizer.transform([text]).toarray()
    disease = model.predict(tfidf)
    
    return disease[0]

symp1 = "Yellowing of skin and eyes, fatigue"
make_pred(knn,symp1)

import joblib
from sklearn.neighbors import KNeighborsClassifier

# Assuming 'knn' is your trained KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(tfidf_train, y_train)

# Save the model using joblib
joblib.dump(knn, 'classification.joblib')


# Take input from user
text = input("Enter Symptoms: ")

# Assuming knn is your trained KNeighborsClassifier model
result = knn.predict(tfidf_vectorizer.transform([text]).toarray())
print(result)

